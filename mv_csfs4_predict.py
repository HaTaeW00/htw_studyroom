import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from transformers import BertTokenizer, BertModel
import pickle
import warnings
warnings.filterwarnings('ignore')

class BertGenreClassifier(nn.Module):
    """BERT ê¸°ë°˜ ì¥ë¥´ ë¶„ë¥˜ ëª¨ë¸ (ë¡œë“œìš©)"""
    
    def __init__(self, n_classes, model_name='bert-base-multilingual-cased', dropout_rate=0.3):
        super(BertGenreClassifier, self).__init__()
        self.bert = BertModel.from_pretrained(model_name)
        self.dropout = nn.Dropout(dropout_rate)
        
        # ì¶”ê°€ ë ˆì´ì–´ë¡œ ì„±ëŠ¥ í–¥ìƒ
        self.pre_classifier = nn.Linear(self.bert.config.hidden_size, 512)
        self.classifier = nn.Linear(512, n_classes)
        self.relu = nn.ReLU()
    
    def forward(self, input_ids, attention_mask):
        outputs = self.bert(
            input_ids=input_ids,
            attention_mask=attention_mask
        )
        pooled_output = outputs.pooler_output
        pooled_output = self.dropout(pooled_output)
        
        # ì¶”ê°€ ë ˆì´ì–´ í†µê³¼
        pre_logits = self.pre_classifier(pooled_output)
        pre_logits = self.relu(pre_logits)
        pre_logits = self.dropout(pre_logits)
        
        return self.classifier(pre_logits)

class MovieGenrePredictor:
    """í›ˆë ¨ëœ ëª¨ë¸ë¡œ ì˜í™” ì¥ë¥´ ì˜ˆì¸¡í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, model_path='movie_genre_bert_model.pth', 
                 tokenizer_path='movie_genre_tokenizer', 
                 label_encoder_path='label_encoder.pkl'):
        print("ğŸ¬ ì˜í™” ì¥ë¥´ ì˜ˆì¸¡ê¸° ì´ˆê¸°í™” ì¤‘...")
        print("=" * 60)
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸš€ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ëª¨ë¸ ì„¤ì • ë¡œë“œ
        print("ğŸ“‚ ëª¨ë¸ ë¡œë“œ ì¤‘...")
        checkpoint = torch.load(model_path, map_location=self.device)
        self.model_config = checkpoint['model_config']
        
        print(f"ğŸ“Š ëª¨ë¸ ì •ë³´:")
        print(f"  - í´ë˜ìŠ¤ ìˆ˜: {self.model_config['n_classes']}")
        print(f"  - ëª¨ë¸ëª…: {self.model_config['model_name']}")
        print(f"  - ìµœëŒ€ ê¸¸ì´: {self.model_config['max_length']}")
        
        # í† í¬ë‚˜ì´ì € ë¡œë“œ
        print("ğŸ”¤ í† í¬ë‚˜ì´ì € ë¡œë“œ ì¤‘...")
        self.tokenizer = BertTokenizer.from_pretrained(tokenizer_path)
        
        # ë¼ë²¨ ì¸ì½”ë” ë¡œë“œ
        print("ğŸ·ï¸ ë¼ë²¨ ì¸ì½”ë” ë¡œë“œ ì¤‘...")
        with open(label_encoder_path, 'rb') as f:
            self.label_encoder = pickle.load(f)
        
        print(f"ğŸ­ í•™ìŠµëœ ì¥ë¥´ ëª©ë¡:")
        for i, genre in enumerate(self.label_encoder.classes_):
            print(f"  {i}: {genre}")
        
        # ëª¨ë¸ ì´ˆê¸°í™” ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
        print("ğŸ¤– ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        self.model = BertGenreClassifier(
            n_classes=self.model_config['n_classes'],
            model_name=self.model_config['model_name']
        )
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        print("âœ… ì˜ˆì¸¡ê¸° ì´ˆê¸°í™” ì™„ë£Œ!")
        print("=" * 60)
    
    def predict_single_text(self, text, show_probabilities=True):
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ì˜ ì¥ë¥´ ì˜ˆì¸¡"""
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° í† í°í™”
        encoding = self.tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=self.model_config['max_length'],
            return_token_type_ids=False,
            padding='max_length',
            truncation=True,
            return_attention_mask=True,
            return_tensors='pt'
        )
        
        input_ids = encoding['input_ids'].to(self.device)
        attention_mask = encoding['attention_mask'].to(self.device)
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        with torch.no_grad():
            outputs = self.model(input_ids, attention_mask)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            _, predicted = torch.max(outputs, dim=1)
        
        # ê²°ê³¼ í•´ì„
        predicted_genre = self.label_encoder.inverse_transform([predicted.cpu().numpy()[0]])[0]
        confidence = probabilities[0][predicted].item()
        
        # ìƒìœ„ 3ê°œ ì˜ˆì¸¡ ê²°ê³¼
        top3_probs, top3_indices = torch.topk(probabilities[0], min(3, len(self.label_encoder.classes_)))
        top3_genres = self.label_encoder.inverse_transform(top3_indices.cpu().numpy())
        top3_results = list(zip(top3_genres, top3_probs.cpu().numpy()))
        
        result = {
            'text': text,
            'predicted_genre': predicted_genre,
            'confidence': confidence,
            'top3_predictions': top3_results
        }
        
        if show_probabilities:
            # ëª¨ë“  ì¥ë¥´ë³„ í™•ë¥ 
            all_probs = probabilities[0].cpu().numpy()
            all_genres = self.label_encoder.classes_
            all_predictions = list(zip(all_genres, all_probs))
            all_predictions.sort(key=lambda x: x[1], reverse=True)
            result['all_predictions'] = all_predictions
        
        return result
    
    def predict_multiple_texts(self, texts, show_details=True):
        """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì˜ ì¥ë¥´ ì˜ˆì¸¡"""
        print(f"\nğŸ¬ {len(texts)}ê°œ í…ìŠ¤íŠ¸ ì¥ë¥´ ì˜ˆì¸¡ ì¤‘...")
        print("=" * 60)
        
        results = []
        for i, text in enumerate(texts):
            print(f"\nğŸ“ ì˜ˆì¸¡ {i+1}/{len(texts)}:")
            print(f"í…ìŠ¤íŠ¸: {text[:60]}{'...' if len(text) > 60 else ''}")
            
            result = self.predict_single_text(text, show_probabilities=False)
            results.append(result)
            
            if show_details:
                print(f"ğŸ¯ ì˜ˆì¸¡ ì¥ë¥´: {result['predicted_genre']}")
                print(f"ğŸ“Š ì‹ ë¢°ë„: {result['confidence']:.3f}")
                print(f"ğŸ† ìƒìœ„ 3ê°œ:")
                for j, (genre, prob) in enumerate(result['top3_predictions']):
                    print(f"   {j+1}. {genre}: {prob:.3f}")
        
        return results
    
    def predict_from_csv(self, csv_file, text_column='ì¤„ê±°ë¦¬', output_file='predictions.csv'):
        """CSV íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì½ì–´ ì˜ˆì¸¡í•˜ê³  ê²°ê³¼ ì €ì¥"""
        print(f"\nğŸ“ CSV íŒŒì¼ì—ì„œ ì˜ˆì¸¡ ìˆ˜í–‰: {csv_file}")
        print("=" * 60)
        
        # CSV íŒŒì¼ ì½ê¸°
        try:
            df = pd.read_csv(csv_file, encoding='utf-8-sig')
            print(f"âœ… íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰")
            print(f"ğŸ“‹ ì»¬ëŸ¼: {list(df.columns)}")
            
            if text_column not in df.columns:
                print(f"âŒ '{text_column}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
        except FileNotFoundError:
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_file}")
            return None
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        texts = df[text_column].tolist()
        predictions = []
        confidences = []
        top2_genres = []
        top2_confidences = []
        
        print(f"\nğŸ”„ ì˜ˆì¸¡ ì§„í–‰ ì¤‘...")
        for i, text in enumerate(texts):
            if pd.isna(text):
                predictions.append("ì•Œ ìˆ˜ ì—†ìŒ")
                confidences.append(0.0)
                top2_genres.append("ì•Œ ìˆ˜ ì—†ìŒ")
                top2_confidences.append(0.0)
                continue
            
            result = self.predict_single_text(str(text), show_probabilities=False)
            predictions.append(result['predicted_genre'])
            confidences.append(result['confidence'])
            
            # 2ìœ„ ì˜ˆì¸¡ ê²°ê³¼
            if len(result['top3_predictions']) >= 2:
                top2_genres.append(result['top3_predictions'][1][0])
                top2_confidences.append(result['top3_predictions'][1][1])
            else:
                top2_genres.append(result['predicted_genre'])
                top2_confidences.append(result['confidence'])
            
            if (i + 1) % 10 == 0:
                print(f"  ì§„í–‰ë¥ : {i+1}/{len(texts)} ({(i+1)/len(texts)*100:.1f}%)")
        
        # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
        df_result = df.copy()
        df_result['ì˜ˆì¸¡_ì¥ë¥´'] = predictions
        df_result['ì‹ ë¢°ë„'] = confidences
        df_result['2ìœ„_ì¥ë¥´'] = top2_genres
        df_result['2ìœ„_ì‹ ë¢°ë„'] = top2_confidences
        
        # ê²°ê³¼ ì €ì¥
        df_result.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        print(f"\nâœ… ì˜ˆì¸¡ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥: {output_file}")
        
        # ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½:")
        prediction_counts = pd.Series(predictions).value_counts()
        for genre, count in prediction_counts.items():
            print(f"  {genre}: {count}ê°œ ({count/len(predictions)*100:.1f}%)")
        
        print(f"\nğŸ“ˆ í‰ê·  ì‹ ë¢°ë„: {np.mean([c for c in confidences if c > 0]):.3f}")
        
        return df_result
    
    def interactive_prediction(self):
        """ëŒ€í™”í˜• ì˜ˆì¸¡ ëª¨ë“œ"""
        print("\nğŸ® ëŒ€í™”í˜• ì¥ë¥´ ì˜ˆì¸¡ ëª¨ë“œ")
        print("=" * 60)
        print("ì˜í™” ì¤„ê±°ë¦¬ë¥¼ ì…ë ¥í•˜ë©´ ì¥ë¥´ë¥¼ ì˜ˆì¸¡í•´ë“œë¦½ë‹ˆë‹¤.")
        print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        print("=" * 60)
        
        while True:
            text = input("\nğŸ“ ì˜í™” ì¤„ê±°ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if text.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
                print("ğŸ‘‹ ì˜ˆì¸¡ê¸°ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            if not text:
                print("âš ï¸ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
            
            print(f"\nğŸ”„ ì˜ˆì¸¡ ì¤‘...")
            result = self.predict_single_text(text)
            
            print(f"\nğŸ¯ ì˜ˆì¸¡ ê²°ê³¼:")
            print(f"  ğŸ“ ì…ë ¥ í…ìŠ¤íŠ¸: {text[:100]}{'...' if len(text) > 100 else ''}")
            print(f"  ğŸ† ì˜ˆì¸¡ ì¥ë¥´: {result['predicted_genre']}")
            print(f"  ğŸ“Š ì‹ ë¢°ë„: {result['confidence']:.3f}")
            
            print(f"\nğŸ… ìƒìœ„ 3ê°œ ì˜ˆì¸¡:")
            for i, (genre, prob) in enumerate(result['top3_predictions']):
                emoji = "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰"
                print(f"    {emoji} {genre}: {prob:.3f}")
            
            if 'all_predictions' in result:
                print(f"\nğŸ“ˆ ì „ì²´ ì¥ë¥´ë³„ í™•ë¥ :")
                for genre, prob in result['all_predictions']:
                    bar_length = int(prob * 20)  # ìµœëŒ€ 20ê¸€ì ë§‰ëŒ€
                    bar = "â–ˆ" * bar_length + "â–‘" * (20 - bar_length)
                    print(f"    {genre:<12} {bar} {prob:.3f}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¬ ì˜í™” ì¥ë¥´ ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    try:
        # ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”
        predictor = MovieGenrePredictor()
        
        # ì‚¬ìš© ì˜ˆì‹œ ì„ íƒ
        print("\nğŸ“‹ ì‚¬ìš© ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ì§ì ‘ ì…ë ¥í•œ í…ìŠ¤íŠ¸ ì˜ˆì¸¡")
        print("2. ì—¬ëŸ¬ ìƒ˜í”Œ í…ìŠ¤íŠ¸ ì˜ˆì¸¡")
        print("3. CSV íŒŒì¼ì—ì„œ ì˜ˆì¸¡")
        print("4. ëŒ€í™”í˜• ì˜ˆì¸¡ ëª¨ë“œ")
        
        choice = input("\nì„ íƒ (1-4): ").strip()
        
        if choice == "1":
            # ë‹¨ì¼ í…ìŠ¤íŠ¸ ì˜ˆì¸¡
            sample_text = "ì£¼ì¸ê³µì´ ì•…ë§ˆì™€ ì‹¸ìš°ë©° ì„¸ìƒì„ êµ¬í•˜ëŠ” íŒíƒ€ì§€ ì•¡ì…˜ ì´ì•¼ê¸°ì…ë‹ˆë‹¤. ë§ˆë²•ê³¼ ê²€ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ê°•ë ¥í•œ ì ë“¤ê³¼ ë§ì„œ ì‹¸ìš°ë©°, ë™ë£Œë“¤ê³¼ í•¨ê»˜ ëª¨í—˜ì„ ë– ë‚©ë‹ˆë‹¤."
            
            print(f"\nğŸ“ ìƒ˜í”Œ í…ìŠ¤íŠ¸ ì˜ˆì¸¡:")
            result = predictor.predict_single_text(sample_text)
            
            print(f"\nğŸ¯ ì˜ˆì¸¡ ê²°ê³¼:")
            print(f"  í…ìŠ¤íŠ¸: {result['text']}")
            print(f"  ì˜ˆì¸¡ ì¥ë¥´: {result['predicted_genre']}")
            print(f"  ì‹ ë¢°ë„: {result['confidence']:.3f}")
            
            print(f"\nğŸ† ìƒìœ„ 3ê°œ:")
            for i, (genre, prob) in enumerate(result['top3_predictions']):
                print(f"    {i+1}. {genre}: {prob:.3f}")
        
        elif choice == "2":
            # ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ì˜ˆì¸¡
            sample_texts = [
                "ë‘ ë‚¨ë…€ê°€ ìš´ëª…ì ìœ¼ë¡œ ë§Œë‚˜ ì‚¬ë‘ì— ë¹ ì§€ëŠ” ë¡œë§¨í‹±í•œ ì´ì•¼ê¸°ì…ë‹ˆë‹¤.",
                "ìš°ì£¼ì—ì„œ ì™¸ê³„ì¸ì´ ì§€êµ¬ë¥¼ ì¹¨ê³µí•˜ê³  ì¸ë¥˜ê°€ ì €í•­í•˜ëŠ” SF ì˜í™”ì…ë‹ˆë‹¤.",
                "ê°€ì¡±ì´ í•¨ê»˜ ì—¬í–‰ì„ ë– ë‚˜ë©° ë²Œì–´ì§€ëŠ” ë”°ëœ»í•˜ê³  ê°ë™ì ì¸ ì´ì•¼ê¸°ì…ë‹ˆë‹¤.",
                "íƒì •ì´ ì—°ì‡„ì‚´ì¸ ì‚¬ê±´ì˜ ì§„ì‹¤ì„ íŒŒí—¤ì¹˜ëŠ” ìŠ¤ë¦´ëŸ¬ ì˜í™”ì…ë‹ˆë‹¤.",
                "ì½”ë¯¹í•œ ìƒí™©ë“¤ì´ ì—°ì†ìœ¼ë¡œ í¼ì³ì§€ëŠ” ì›ƒìŒì´ ê°€ë“í•œ ì˜í™”ì…ë‹ˆë‹¤."
            ]
            
            results = predictor.predict_multiple_texts(sample_texts)
        
        elif choice == "3":
            # CSV íŒŒì¼ ì˜ˆì¸¡
            csv_file = input("CSV íŒŒì¼ëª…ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            text_column = input("í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ê¸°ë³¸ê°’: ì¤„ê±°ë¦¬): ").strip()
            if not text_column:
                text_column = "ì¤„ê±°ë¦¬"
            
            output_file = input("ê²°ê³¼ íŒŒì¼ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ê¸°ë³¸ê°’: predictions.csv): ").strip()
            if not output_file:
                output_file = "predictions.csv"
            
            predictor.predict_from_csv(csv_file, text_column, output_file)
        
        elif choice == "4":
            # ëŒ€í™”í˜• ëª¨ë“œ
            predictor.interactive_prediction()
        
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
        
    except FileNotFoundError as e:
        print(f"âŒ í•„ìš”í•œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        print("ğŸ’¡ ë¨¼ì € ëª¨ë¸ í›ˆë ¨ì„ ì‹¤í–‰í•˜ì„¸ìš”: python improved_model.py")
    
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()