import pandas as pd
import numpy as np
from sklearn.utils import resample
from sklearn.model_selection import train_test_split
import csv  # ì¶”ê°€

def improved_balance_dataset(input_file='processed_data.csv', output_file='improved_balanced_second_ps.csv'):
    """ê°œì„ ëœ ë°ì´í„° ë°¸ëŸ°ì‹±"""
    print("ğŸ¬ ê°œì„ ëœ ë°ì´í„° ë¶ˆê· í˜• í•´ê²° ì‹œì‘")
    print("=" * 60)
    
    df = pd.read_csv(input_file, encoding='utf-8-sig')
    df['ì¥ë¥´_ë‹¨ì¼'] = df['ì¥ë¥´'].apply(lambda x: x.split(',')[0].strip())
    
    print("ğŸ“Š í˜„ì¬ ì¥ë¥´ ë¶„í¬:")
    genre_counts = df['ì¥ë¥´_ë‹¨ì¼'].value_counts()
    print(genre_counts)
    
    # 1. ë” ê´€ëŒ€í•œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜ (10ê°œ ì´ìƒ)
    min_samples = 10
    valid_genres = genre_counts[genre_counts >= min_samples].index
    df_filtered = df[df['ì¥ë¥´_ë‹¨ì¼'].isin(valid_genres)].copy()
    
    print(f"\nğŸ—‘ï¸ {min_samples}ê°œ ë¯¸ë§Œ í´ë˜ìŠ¤ ì œê±°:")
    removed_genres = set(genre_counts.index) - set(valid_genres)
    for genre in removed_genres:
        print(f"  - {genre}: {genre_counts[genre]}ê°œ")
    
    # 2. ì ì‘ì  íƒ€ê²Ÿ ìƒ˜í”Œë§ (í´ë˜ìŠ¤ë³„ë¡œ ë‹¤ë¥¸ ëª©í‘œ ì„¤ì •)
    print(f"\nğŸ”„ ì ì‘ì  ë°ì´í„° ë°¸ëŸ°ì‹± ì¤‘...")
    
    balanced_dfs = []
    
    for genre in df_filtered['ì¥ë¥´_ë‹¨ì¼'].unique():
        genre_data = df_filtered[df_filtered['ì¥ë¥´_ë‹¨ì¼'] == genre]
        current_count = len(genre_data)
        
        # í´ë˜ìŠ¤ë³„ ì ì‘ì  ëª©í‘œ ìƒ˜í”Œ ìˆ˜
        if current_count >= 100:
            target_samples = 80  # í° í´ë˜ìŠ¤ëŠ” 80ê°œë¡œ
        elif current_count >= 50:
            target_samples = 60  # ì¤‘ê°„ í´ë˜ìŠ¤ëŠ” 60ê°œë¡œ  
        elif current_count >= 30:
            target_samples = 45  # ì‘ì€ í´ë˜ìŠ¤ëŠ” 45ê°œë¡œ
        else:
            target_samples = min(35, current_count * 2)  # ë§¤ìš° ì‘ì€ í´ë˜ìŠ¤ëŠ” ìµœëŒ€ 2ë°°
        
        if current_count > target_samples:
            # ì–¸ë”ìƒ˜í”Œë§ (ëœë¤ì´ ì•„ë‹Œ ë‹¤ì–‘ì„± ê³ ë ¤)
            genre_balanced = genre_data.sample(n=target_samples, random_state=42)
            print(f"  ğŸ“‰ {genre}: {current_count} â†’ {target_samples} (ì–¸ë”ìƒ˜í”Œë§)")
        else:
            # ì œí•œì  ì˜¤ë²„ìƒ˜í”Œë§
            if current_count < target_samples:
                # ì›ë³¸ + ì¼ë¶€ ë³µì œ
                original_samples = current_count
                additional_needed = target_samples - current_count
                
                genre_balanced = pd.concat([
                    genre_data,  # ì›ë³¸ ì „ì²´
                    genre_data.sample(n=additional_needed, replace=True, random_state=42)  # ì¶”ê°€ ìƒ˜í”Œ
                ])
                print(f"  ğŸ“ˆ {genre}: {current_count} â†’ {target_samples} (ì œí•œì  ì˜¤ë²„ìƒ˜í”Œë§)")
            else:
                genre_balanced = genre_data
                print(f"  âœ… {genre}: {current_count} (ë³€ê²½ ì—†ìŒ)")
        
        balanced_dfs.append(genre_balanced)
    
    # ê²°í•© ë° ì…”í”Œ
    df_balanced = pd.concat(balanced_dfs, ignore_index=True)
    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)
    df_balanced['ë²ˆí˜¸'] = range(1, len(df_balanced) + 1)
    df_balanced = df_balanced.drop('ì¥ë¥´_ë‹¨ì¼', axis=1)
    
    # ì €ì¥ (ëª¨ë“  ì»¬ëŸ¼ ìŒë”°ì˜´í‘œ)
    df_balanced.to_csv(output_file, index=False, encoding='utf-8-sig', quoting=csv.QUOTE_ALL)
    
    print(f"\nğŸ“Š ê°œì„ ëœ ë°¸ëŸ°ì‹± ê²°ê³¼:")
    print(f"  ì›ë³¸: {len(df)}ê°œ â†’ ë°¸ëŸ°ì‹±: {len(df_balanced)}ê°œ")
    
    # ìµœì¢… ë¶„í¬ í™•ì¸
    print(f"\nğŸ­ ìµœì¢… ì¥ë¥´ ë¶„í¬:")
    final_counts = df_balanced['ì¥ë¥´'].apply(lambda x: x.split(',')[0].strip()).value_counts()
    print(final_counts)
    
    return df_balanced

def split_train_evaluation_data_v2(balanced_df, train_file='improved_train_data.csv', eval_file='improved_evaluation_data.csv', test_size=0.2, random_state=42):
    """ê°œì„ ëœ ë°ì´í„° ë¶„í• """
    print("\n" + "=" * 60)
    print("ğŸ“‚ ê°œì„ ëœ í›ˆë ¨ìš©/í‰ê°€ìš© ë°ì´í„° ë¶„í• ")
    print("=" * 60)
    
    single_genres = balanced_df['ì¥ë¥´'].apply(lambda x: x.split(',')[0].strip())
    
    # 8:2 ë¶„í• 
    train_data, eval_data = train_test_split(
        balanced_df,
        test_size=test_size,
        random_state=random_state,
        stratify=single_genres
    )
    
    # ë²ˆí˜¸ ì¬ì •ë ¬
    train_data = train_data.copy().reset_index(drop=True)
    eval_data = eval_data.copy().reset_index(drop=True)
    train_data['ë²ˆí˜¸'] = range(1, len(train_data) + 1)
    eval_data['ë²ˆí˜¸'] = range(1, len(eval_data) + 1)
    
    # ì €ì¥ (ëª¨ë“  ì»¬ëŸ¼ ìŒë”°ì˜´í‘œ)
    train_data.to_csv(train_file, index=False, encoding='utf-8-sig', quoting=csv.QUOTE_ALL)
    eval_data.to_csv(eval_file, index=False, encoding='utf-8-sig', quoting=csv.QUOTE_ALL)
    
    print(f"âœ… ê°œì„ ëœ ë°ì´í„° ë¶„í•  ì™„ë£Œ!")
    print(f"ğŸ“Š ë¶„í•  ê²°ê³¼:")
    print(f"  í›ˆë ¨ìš©: {len(train_data)}ê°œ â†’ {train_file}")
    print(f"  í‰ê°€ìš©: {len(eval_data)}ê°œ â†’ {eval_file}")
    
    # ì¥ë¥´ë³„ ë¶„í¬
    print(f"\nğŸ­ í›ˆë ¨ìš© ì¥ë¥´ ë¶„í¬:")
    train_counts = train_data['ì¥ë¥´'].apply(lambda x: x.split(',')[0].strip()).value_counts()
    print(train_counts)
    
    print(f"\nğŸ­ í‰ê°€ìš© ì¥ë¥´ ë¶„í¬:")
    eval_counts = eval_data['ì¥ë¥´'].apply(lambda x: x.split(',')[0].strip()).value_counts()
    print(eval_counts)
    
    return train_data, eval_data

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¬ ê°œì„ ëœ ì˜í™” ë°ì´í„° ì „ì²˜ë¦¬ v2")
    print("=" * 60)
    
    try:
        # ê°œì„ ëœ ë°¸ëŸ°ì‹±
        balanced_df = improved_balance_dataset(
            input_file='processed_data.csv',
            output_file='improved_balanced_second_ps.csv'
        )
        
        # ê°œì„ ëœ ë¶„í• 
        train_data, eval_data = split_train_evaluation_data_v2(
            balanced_df,
            train_file='improved_train_data.csv',
            eval_file='improved_evaluation_data.csv'
        )
        
        print(f"\nğŸ‰ ê°œì„ ëœ ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“ ìƒì„±ëœ íŒŒì¼:")
        print(f"  1. improved_balanced_second_ps.csv")
        print(f"  2. improved_train_data.csv ({len(train_data)}ê°œ)")
        print(f"  3. improved_evaluation_data.csv ({len(eval_data)}ê°œ)")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()